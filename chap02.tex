\chapter{Scala programming language}
\label{chap:scala}

The adaptive framework introduced in this work was created in Scala \cite{noauthor_scala_nodate}, an advanced programming language that is built upon the JVM runtime. This chapter will present a brief overview of some of the language aspects that are important for the API design.

The basic paradigm of Scala is object-orientation - it is based on the same principles as Java and its language constructs get mapped to Java bytecode constructs upon compilation. In addition to this, Scala aims to enable full-scale functional development in the same context as well. It is quite a unique concept among the common and production-used languages, which tend to adopt some functional features (higher-order functions, lambdas), but stop at some point and do not add more advanced mechanisms (type classes, monads).

\section{Methods and functions in Scala}
\label{sec:metandfun}

There is an important difference between methods and functions in Scala, even though the names are often used interchangeably in the literature. Methods have the same concept as in Java and other object oriented languages - they are an integral, compile-time part of their class and the only context that they can refer to is their class instance, their arguments and static members. They cannot be passed around, so no additional context is needed. Every invocation has to be performed on a class instance, allowing the compiler to correctly assign the \textit{this} reference. Simple example of a method can be the following:

\lstset{style=Scala}
\begin{lstlisting}
class Class {
  def method(arg: String): String = 
    s"Called method($arg) on $this"
}
val obj = new Class()
println(obj.method("Hello"))
\end{lstlisting}

Functions are first-class values that have a type and can be passed into other functions or methods, or be part of expressions. Internally, they are represented as closure objects, carrying around their context and the compiled code stored as a method in the closure type. They are created using lambda expressions:

\lstset{style=Scala}
\begin{lstlisting}
val function: (String) => Unit = 
  arg => println(obj.method(arg))
function("Hello again!")
List("One", "Two", "Three").foreach(function)
\end{lstlisting}

Each lambda expression is converted into an automatically generated class upon compilation, and its usages in the code are replaced by instantiation of the class. The \lstinline|obj| reference is \textit{captured}\footnote{Becomes an attribute of the class and is passed in in the constructor.} inside the closure, the function is not tied to any class. 

The methods represent the basic building block of the object-oriented approach, being the single point that can access or modify the private internal state of the object. The functions are a foundation of the functional part of the language, because they can be passed around as values.

We can create an illusion of functions behaving like methods by declaring them as a class fields:

\lstset{style=Scala}
\begin{lstlisting}
class Class(val field: String) {
  val print: () => Unit = () => println(field)
}
val instance = new Class("Test")
instance.print()
\end{lstlisting}

In this case, the class contains an immutable field \inlinecode{print} containing a function. The function references another field, which is stored in the function closure. And the invocation is done by accessing the \inlinecode{print} field and invoking the result.

%TODO: Function limitations - generics, etc.

\subsection{Function types}
\label{subsec:functiontypes}

The first-class value functions have to be anchored somewhere in the Scala type system in order for the type inference, type checking and other mechanisms to work correctly. The type of a function is unambiguously determined by its signature, i.e. the number and types of arguments and the type of the return type. Consequentially, the function types have to be generic and able to accept different numbers of type arguments.

Scala as a language does not support variadic generic types (as opposed to languages like C++), so there has to be a different type with different number of type arguments for every possible number of arguments of a function. Currently, there are traits for functions accepting 0 to 22 arguments\footnote{In the code snippets, the type and argument lists will be shortened using the ... notation. The code would have to be expanded in order to be compilable. Analogically, an N will be used in place of a number in the type or type argument names.}:

\lstset{style=Scala}
\begin{lstlisting}
trait Function0[+R]
...
trait Function22[-T1, ..., -T22, +R]
\end{lstlisting}

These traits have syntactic aliases in the language:

\lstset{style=Scala}
\begin{lstlisting}
() => R
...
(T1, ..., T22) => R
\end{lstlisting}

Functions with more than 22 arguments cannot exist in Scala and have to be replaced by function accepting tupled\footnote{Scala has generic tuple types and syntactic shortcuts for tuple: \inlinecode{(T1, ..., TN)}.} arguments. The necessity to represent functions with various argument numbers as multiple traits leads to code duplication wherever we want to interact directly with function types and support any argument number.

Function invocation is represented by an \inlinecode{apply} method declared in all the function trait types with the following signature:
\lstset{style=Scala}
\begin{lstlisting}
def apply(v1: T1, ..., vN: TN): R
\end{lstlisting}

Scala automatically converts the \inlinecode{()} operator on any instance to an invocation of the \inlinecode{apply} method on the same instance with given arguments. This works for all the class instances, we can make any type callable in Scala.

The default function implementations in Scala are created using lambda expressions, which are compiled to a separate closure class that extends the corresponding function trait type and has the code in the \inlinecode{apply} method implementation. We can, however, create our own function trait implementations that will be treated by all Scala code and libraries in the same way as any function. The only thing required is to provide implementation of the \inlinecode{apply} method.

\subsection{Eta-expansion}
\label{subsec:etaexpansion}

%TODO: Reference to the eta-expansion
As the strengths of Scala lie in its functional features, it is often handy to be able to convert methods to functions. This process is called \textit{eta-expansion} and is quite straightforward - we just need to create a function which delegates the call to the method:

\lstset{style=Scala}
\begin{lstlisting}
val methodFunction: (String) => String = arg => method(arg)
\end{lstlisting}

Scala has a special operator for the conversion that generates the function automatically:

\lstset{style=Scala}
\begin{lstlisting}
val methodFunction = method _
\end{lstlisting}

And in some expression contexts, this conversion becomes implicit:

\lstset{style=Scala}
\begin{lstlisting}
List("One", "Two", "Three").map(method)
\end{lstlisting}

In this example, the conversion is implicitly applied to an argument of a method in order to meet the required type. The expansion in this case will be always implicit, unless one of the following conditions is met:
\begin{enumerate}
	\item The method has overloads.
	\item There is an implicit typecast required from the expanded type to the parameter type.
\end{enumerate}

Unfortunately, the same kind of automatic expansion is not performed on the target of a method call. The following example will not compile:

\lstset{style=Scala}
\begin{lstlisting}
val composed = method.andThen(method)
\end{lstlisting}

The explicit eta-expansion operator is needed for it in order to work.

\lstset{style=Scala}
\begin{lstlisting}
val composed = (method _).andThen(method)
\end{lstlisting}

%TODO: Generic methods vs. functions

%TODO: methods vs. functions in scala, eta expanstion

%TODO: multiple combination

%TODO: covariance and contravariance

\section{DSLs in Scala}
\label{sec:dsls}

DSL (Domain Specific Language) is a type of a programming language that is narrowly focused on solving a specific class of problems. It offers a higher level of expressiveness and therefore is easier to use than general-purpose languages. There is a large variety of areas where the DSLs are often employed, e.g. mathematical computations (R, MATLAB), database queries (SQL), build scripts (make, Ant), parsing (regular expressions) and many more.

In order to simplify the process of creating a new DSL, it is often implemented inside an existing general-purpose language, using objects and references to substitute the keywords of the language. The DSL is represented by a set of class definitions and can be distributed as a library. This significantly speeds up the development process - there is no need to implement the syntax parser, compiler, the end user does not have to have any specialized tools to actually use the language. A program written in such a language will just get compiled (if its necessary) and executed. The DSL code will create a certain object structure in runtime, interpret it and carry out required tasks.

These DSLs became recently very popular for defining configurations, build and deployment processes - an example could be the Gradle scripting language \cite{noauthor_gradle_nodate}, which is actually a DSL in Groovy, or the Recipe DSL for Chef \cite{noauthor_chef_nodate} built atop of the Ruby language.

%TODO: Gradle and Chef references

DSLs can be efficiently implemented only in languages with flexible-enough syntax, which do not limit it too much. Scala belongs to this class of languages, along with for example Groovy. A code in one of the Scala DSLs, the ScalaTest framework \cite{noauthor_scalatest:_2017}, can look the following way:

\lstset{style=Scala}
\begin{lstlisting}
an [Exception] should be thrownBy { s.charAt(-1) }
greeting should equal ("hi") (after being lowerCased)
\end{lstlisting}

The above is a valid Scala code that can be compiled and run, and is used by the framework to express unit test assertions.

\subsection{Infix operators}
\label{subsec:infixops}

One of the features that support both the functional flavor of Scala and the DSL building capabilities is the possibility to use methods as infix operators. Any method that has exactly one argument can be called using the following special syntax:

\lstset{style=Scala}
\begin{lstlisting}
class RichInt {
  def plus(other: RichInt) = ???
}
...
val res = x plus y
\end{lstlisting}

This syntax is even more powerful if we take into consideration that Scala allows the methods to have non-alphanumeric names:

\lstset{style=Scala}
\begin{lstlisting}
def +(other: RichInt) = ???
...
val res = x + y
\end{lstlisting}

This approach enables us to use the infix syntax with existing methods and with methods that were not designed with the intention to be used that way. It has, however, a downside as well - it does not allow us to create an infix operator that would accept a certain type as its first argument without actually changing the definition of that type and adding the method to its definition. Scala does not directly support declaring extension methods\footnote{Methods, that can be added to existing types without changing them, they have access only to the public API of the type.} on types (unlike C\#, Kotlin and other languages) and so the only way to solve this problem is to introduce implicit typecast to a custom type and to add the infix operator as a method to it.

\section{Implicit conversions}
\label{sec:implicits}

Scala supports defining a custom set of implicit conversion methods that will be automatically called throughout the code. The conversion from type \inlinecode{T} to type \inlinecode{U} is a method or a function with one argument of type \inlinecode{T} and a return value of type \inlinecode{U} declared with the \inlinecode{implicit} attribute:

\lstset{style=Scala}
\begin{lstlisting}
implicit def myConversion(t: T): U = ???
\end{lstlisting}

Now wherever an expression of type \inlinecode{T} is either used in a place where the type \inlinecode{U} is expected, or a selector (method or field name) unknown to type \inlinecode{T} but known to type \inlinecode{U} is applied to it, a call of our \inlinecode{myConversion} method is generated to convert the type. The implicit method has to be in scope at the moment of the typecast, otherwise the compiler will not be able to locate it. The common practice is to gather all the implicit conversion methods into an object called either \inlinecode{implicits} or \inlinecode{Implicits}, and let the user import all the methods of the object whenever he needs it:

\lstset{style=Scala}
\begin{lstlisting}
import my.project.Implicits._
\end{lstlisting}

The most typical use-case for the implicit conversions is adding new functionality to existing types. This can be used in DSLs as well, like in the following simple example:

\lstset{style=Scala}
\begin{lstlisting}
class RichInt(val i: Int) {
  def times[T](fun: () => T): Unit =
    Seq.range(0, i).foreach(_ => fun())
}
implicit def intToRichInt(i : Int): RichInt = new RichInt(i)
def greet(): Unit = println("Hello!")
4 times greet
\end{lstlisting}

In other languages (C\#, Kotlin), the same goal is achieved using extension methods, which is less flexible but more transparent solution.

Implicit conversions are considered a potentially dangerous feature, therefore they have to be manually enabled either by a Scala compiler switch, or by importing \inlinecode{scala.language.implicitConversions} in the scope.

\subsection{Implicit arguments}
\label{subsec:implicit_args}

In addition to being automatically called for conversions, the implicit methods and values can be automatically passed into method calls as arguments. If an argument of a method is marked with the implicit attribute, it does not have to be specified at invocation, it will be filled automatically by an identifier with matching type that is accessible at the point of the call and is marked implicit itself. The actual argument then, again, behaves as being marked implicit within the function. This can be used to propagate implicit values throughout a chain of calls.

The most common application of implicit arguments is enabling the usage of implicit typecasts with type arguments - a method can set bound on its type arguments by requiring implicit conversion to a different type. In the Scala terminology, the type has to be \textit{viewable} as that type.

\lstset{style=Scala}
\begin{lstlisting}
def bubbleSort[A](list: List[A])(implicit ord: A => Ordered[A]): List[A] = ???
\end{lstlisting}

There used to be a specialized syntax called \textit{View bounds} in earlier versions of Scala to support this usage, but it has been deprecated:

\lstset{style=Scala}
\begin{lstlisting}
def bubbleSort[A <% Ordered[A]](list: List[A]): List[A] = ???
\end{lstlisting}

The typical use case of the described scenario is simulating \textit{type classes} from functional languages like Haskell. A generic trait with required methods (representing the type class and its functions) is created:

\lstset{style=Scala}
\begin{lstlisting}
trait Incrementable[A] {
  def increment: A
}
\end{lstlisting}

 Adding a member to the type class is done by creating an implementation of the trait with the type fixed and an implicit method that provides the conversion from the original type:
 
 \lstset{style=Scala}
 \begin{lstlisting}
implicit def intIsIncrementable(i: Int): Incrementable[Int] = new Incrementable[Int] {
  override def increment: Int = i + 1
}
 \end{lstlisting}
 
 Now, whenever this conversion method is accessible, \inlinecode{Int} can be used as \inlinecode{Incrementable[Int]} and in addition, can be passed to any generic function that requires the argument to be \textit{viewable} as \inlinecode{Incrementable}:
 
  \lstset{style=Scala}
 \begin{lstlisting}
 def incrementValue[K, V](map: mutable.Map[K, V], key: K)
                                (implicit inc: V => Incrementable[V]) =
   data.update(key, data(key).increment)
  \end{lstlisting}
  
Note that the value of an implicit argument can be specified manually at the time of the call, and it does not necessarily have to be implicit in the calling scope. In such a situation, it will be treated as implicit only inside the method scope.

\section{Def Macros}
\label{sec:defmacros}

Def Macros are quite a unique feature among all the widely used programming languages. It allows a library writer to include a code that will be executed upon compilation of the unit which references the library. This basically means that simple compiler extensions in Scala can behave like libraries, can be distributed and used as common \textit{jar} files.

The API is very simple - there are methods marked as \textit{macros} in the library code. Whenever a call of this method is being compiled, the compiler invokes the macro implementation, which is a normal Scala method. It will receive an AST\footnote{Abstract Syntax Tree - the product of the syntax analysis of a source code} of the arguments passed to the original method and produce another AST, which will replace the call in the code.

%TODO: Example, usages, source

The only limitation is that the macro cannot be used in the same compilation unit where its declaration and implementation is, as the Scala compiler has to have access to the already compiled implementation when building the usages.

\subsection{Building syntax trees}
\label{subsec:buildingast}

The macro usually has to be able to perform two steps:

\begin{enumerate}
	\item Parse the argument AST
	\item Build the replacement AST
\end{enumerate}

The syntax trees are represented by tree node classes with \inlinecode{apply()} and \inlinecode{unapply()} methods accepting and returning their descendants. We need to deconstruct the input, preferably using pattern matching, and then build an output tree by creating a new chain of nodes. For both actions, it is essential to know the structure of valid syntax trees that correspond to the code.

Unfortunately, there is not a lot of documentation available for the syntax tree structure. The official Scala documentation has only a few examples and the types in the code lack the documentation as well (as of Scala 2.11). One of the most complete overviews of the syntax tree nodes and its building scheme can be found in \cite{noauthor_wolfe:_2017}.

One of the possible options to find out how certain expressions are parsed into ASTs is to create a simple macro that will accept any expression, print its AST and replace itself by the same expression again:

\lstset{style=Scala}
\begin{lstlisting}
def printAst(arg: Any): Any = macro printAst_impl

def printAst_impl(c: Context)(arg: c.Expr[Any]): c.Expr[Any] = {
  import c.universe._
  println(showRaw(arg.tree))
  arg
}
\end{lstlisting}

The output that is written to \textit{stdout} by a macro implementation is displayed as a warning in the compilation process, so there is no need to run the program to see the results of \inlinecode{printAst()}, it is sufficient just to compile it.

For example, \inlinecode{printAst(x + 1)} produces the following compile-time warning:

\lstset{style=Dump}
\begin{lstlisting}
Warning:scalac: Block(List(), Function(List(ValDef(Modifiers(PARAM | SYNTHETIC), TermName("i"), TypeTree(), EmptyTree)), Apply(Select(This(TypeName("MacroTest")), TermName("increment")), List(Ident(TermName("i"))))))
\end{lstlisting}


