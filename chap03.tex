\chapter{API design and usage}
\label{chapter:api}

API (Application Programming Interface) is a key component of every framework or library. It defines how a stand-alone piece of code (a function, class, module, or even entire running application) interacts with its environment. This includes the possible calls / requests, format of the data that is passed in as arguments and the data that is received as a result of the action.In our case, the API will be used to access functionality of our library from library user's own code. 

\section{Basic API requirements}

The library itself should not require much interaction from the programmer. The usage would be based on performing some initial configuration, marking method implementations that are interchangeable, and then calling repeatedly either one of the methods marked, or some special method, and receiving correct results from one of the implementations. The typical use-case of our API could be described in the following way:

\textit{User has a class with two methods, \inlinecode{method1()} and \inlinecode{method2()}, and uses the framework simple API to create a third method in the same class, \inlinecode{method()}, that adaptively uses one of the other two methods. If he wants to change the behavior of the adaptation (method selection) process, he can do it directly in the definition of the \inlinecode{method()}.}

The important point is that we want the result of combining the methods to be transparent, a part of the API. The caller shouldn't know and shouldn't have to know that he is calling a method that is somehow special. This allows us to locate the adaptation framework interaction to one place and gives us the possibility to quickly replace it or remove it completely.

We can make a list of the \textbf{basic requirements}:
\begin{enumerate}
	\item Create a method by combining two or more different methods (stating that they can be called interchangeably)
	\item Define some basic adaptation behavior for the function
	\item Make some more complex configuration changes for the whole library
\end{enumerate}

\section{Goals of the API design}

For a library that will be used repeatedly by a variety of other developers, the API design is crucial and has two principal goals:

\begin{enumerate}
	\item Keeping the API calls simple in basic use cases
	\item Giving the caller freedom to customize more in more complicated use cases
\end{enumerate}

% TODO: Macros

\section{Possible API drafts}

\subsection{Method annotations}

\subsection{Untyped reflection interface}

\subsection{Direct interaction}

\subsection{Function composition}

Scala is a programming language that has absorbed a lot of concepts from the functional programming language world. Above all the key concept that functions are \textit{first-class values} and can be passed around the same way as code. A little complication is that functions and methods are a different concept in Scala (as explained in section \ref{sec:metandfun}). So let's first consider the case where we work solely with functions.

The goal of our API is to allow the programmer to link together two or more functions and receive one universal function that will decide which one to call. This could be solved using a \textit{higher-order function}\footnote{A function whose arguments and return type are other functions.}, which is a common approach in functional languages, well known from list manipulating patterns like \textit{map}, \textit{filter}, or \textit{fold}.

Scala supports this approach both in language features and in its standard libraries - as mentioned in \ref{sec:metandfun}, functions are first class values and can be arguments of other methods or functions. A simple example could be function composition, which is implemented as a method on the function type traits (see \ref{subsec:functiontypes}):

\lstset{style=Scala}
\begin{lstlisting}
val timesTwo = (x: Int) => { x * 2 }
val plusOne = (x: Int) => { x + 1 }
val timesTwoPlusOne = timesTwo.andThen(plusOne)
\end{lstlisting}

We can achieve even more readable and natural looking code if we take advantage of the infix operator syntax (see \ref{subsec:infixops}):

\lstset{style=Scala}
\begin{lstlisting}
val timesTwoPlusOne = timesTwo andThen plusOne
\end{lstlisting}

Chaining of the methods / operators is possible as well:

\lstset{style=Scala}
\begin{lstlisting}
val manyOperations = timesTwo andThen plusOne andThen plusOne andThen timesTwo
\end{lstlisting}

Inspired by this readable and very simple syntax to compose functions which relies on only the basic syntactic features of Scala, we can try to design the API of the selection mechanism in the exactly same way:

\lstset{style=Scala}
\begin{lstlisting}
def or(fun: (T) => R): (T) => R = ???
...
val funAorB = funA or funB
\end{lstlisting}

\subsubsection{Advantages}
\subsubsection{Disadvantages}
\subsubsection{Consequences}

\section{Scala API implementation}

\subsection{Consequences of the choice}

The \lstinline|or()| method, in order to be used as an infix operator, has to be defined on the type that represents the first argument, in this case, a function. More specifically, any of the function types mentioned in \ref{subsec:functiontypes}. Because Scala doesn't support extension methods, we need to introduce a new type for functions containing this behavior, and an implicit conversion from the normal function type.

Theoretically, we need to cover all of the 23 original function type traits with custom type extensions, which will be mostly duplicated code - this reduces the maintainability and flexibility of the code. The trait files can be generated, but any change has to be reflected in the generating script first, before re-generating the code.

\subsection{Using the API with methods}
\label{subsec:apimethods}

Another thing to consider is that in most cases, the selection mechanism will be used with methods, not functions. As mentioned in \ref{subsec:etaexpansion}, Scala allows a simple conversion from methods to functions, which can be implicit in some cases. It would be preferable to omit the explicit conversions wherever it's possible.

We can try combining methods with Scala function composition:
\lstset{style=Scala}
\begin{lstlisting}
val composed = method1 andThen method2
\end{lstlisting}

This code won't compile with a suggestion to add the \lstinline|_| operator to \lstinline|method1| in order to treat it as a partially applied function (and to be able to call \lstinline|andThen()| method). Scala unfortunately doesn't perform implicit eta-expansion on the target of a method call. So after fixing the example, we get a fully working result:

\lstset{style=Scala}
\begin{lstlisting}
val composed = method1 _ andThen method2
\end{lstlisting}

On \lstinline|method2|, the eta-expansion is performed implicitly, because it's an argument of a method without overloads.

Now, in order to keep the same pattern working, we need to declare our \lstinline|or()| method in the following way:
\lstset{style=Scala}
\begin{lstlisting}
trait FunctionAdaptor[T, R] extends (T) => R {
  def or(fun: (T) => R): (T) => R = ???
}
\end{lstlisting}

If there is a suitable implicit conversion from \lstinline|(T) => R| to \lstinline|FunctionAdaptor[T,R]|, it is possible to use it in the same way as the \lstinline|andThen()| method:

\lstset{style=Scala}
\begin{lstlisting}
val fun = method1 _ or method2 or method3
\end{lstlisting}

Chaining in this case will not cause any problem, because the return value of the \lstinline|or()| method has the type of \lstinline|(T) => R| and can be combined again. It is, however, necessary to identify the case in the implementation and to handle it, otherwise, we would be building a tree of function pairs to choose from instead of choosing from all N values at once.

Note that changing or overloading the \lstinline|or()| method to accept directly \lstinline|FunctionAdaptor[T,R]| to handle the chaining case would break the syntax, as there would be implicit typecast (or even a function overload) blocking the implicit eta-expansion (see \ref{subsec:etaexpansion}). The following example demonstrates the result:

\lstset{style=Scala}
\begin{lstlisting}
def or(fun: FunctionAdaptor[T,R]): (T) => R = ???
...
val fun = method1 _ or method2 _  or method3
\end{lstlisting}

%TODO: Def macros?
%TODO: Move to a different section

\section{The API problems and their solution}

\subsection{Covariance and contravariance}
%TODO: Object-oriented polymorphism
% http://milessabin.com/blog/2012/04/27/shapeless-polymorphic-function-values-1/

So far, all mentioned usages of the \lstinline|or()| method were limited to functions with the same signatures. Quite common case, however, might be combining multiple functions with slightly different argument and return value types, typically one being a specialized version of the other. For example:

%TODO: replace this example:

The two functions can't be joined using the \lstinline|or()| method, because \lstinline|bubbleSort()| is defined on a more general type than \lstinline|radixSort()|. Let's examine simplified case with more combinations:

\lstset{style=Scala}
\begin{lstlisting}
def fun1(arg: Any): String = ???
def fun2(arg: String): Any = ???
def fun3(arg: String): String = ???

val fun4 = fun3 _ or fun2
val fun5 = fun2 _ or fun3
val fun6 = fun3 _ or fun1
val fun7 = fun1 _ or fun3
\end{lstlisting}

We receive compilation error on lines 5 and 8, in the definition of \lstinline|fun4| and \lstinline|fun7|. Lines 6 and 7 compile correctly. These are the cases where:

\begin{enumerate}
	\item Return type of the function passed in as an argument is a subtype of the return type of the target function
	\item Argument type of the function passed in as an argument is a supertype of the argument type of the target function
\end{enumerate}

The function types (represented as traits) in Scala are defined in the following way:
\lstset{style=Scala}
\begin{lstlisting}
trait Function1[-T1, +R] extends AnyRef
\end{lstlisting}

The type arguments representing the function arguments are defined as contravariant and the type argument representing the return value of the function is defined as covariant. This leads to \lstinline|(String) => String| being a subtype of \lstinline|(String) => Any| and to \lstinline|(Any) => String| being a subtype of \lstinline|(String) => String|. So the \lstinline|or()| method is working flawlessly for the \lstinline|fun5| and \lstinline|fun6|.

Taking into account that \lstinline|or()| is behaving like a commutative infix operator, we would like it to work in the other two cases as well. The two functions combined will always be in a subtype - supertype relation The signature of the function returned has to match the more limiting signature, i.e. the signature,

\begin{lstlisting}
def funA(arg: A): A = ???
def funB(arg: B): B = ???
val funAB: (B with A) => Object = funA _ or funB
\end{lstlisting}

%TODO: Comment case & listing

As we can see, these are the cases where:

\begin{enumerate}
	\item The output type of the function that is passed as an argument is more general (superclass) than the output type of the target function
	\item The argument type of the function that is passed as an argument is more specific (subclass) than the argument type of the target function
\end{enumerate}

This is a case where covariance and contravariance of the type arguments of the functions that our \lstinline|or()| method accepts should be taken into account. Let's consider the following type of the first function:

\lstset{style=Scala}
\begin{lstlisting}
(A) => B
\end{lstlisting}

This function should be combinable using \lstinline|or()| method with any 

\subsection{Generic methods}

%TODO: Solution suggestion - OOP approach, genericity in classes

%TODO: How to solve this issue?

Functions have one major limitation in Scala - they can't have any generic arguments. The signature of a function always has all the argument and return value types specified at compile-time. If we perform the eta-expansion on a generic method, we have to specify the type argument, otherwise, the type arguments will be fixed as Nothing and the function won't be callable:

\lstset{style=Scala}
\begin{lstlisting}
def makeTuple[A, B](a: A, b: B): (A, B) = (a, b)
val fun1 = makeTuple _
// fun1: (Nothing, Nothing) => (Nothing, Nothing)
val fun2 = makeTuple[Int, String] _
// fun2: (Int, String) => (Int, String)
\end{lstlisting}

As the \lstinline|or()| method performs combination of functions into another function, we automatically lose all the generic types involved in the original methods we are expanding and then combining. We can, however, take advantage of the fact that the type arguments being explicitly set in the process of eta-expansion can be generic types of an enclosing structure (generic class or generic method). With this approach, there are two possible patterns of achieving genericity in combined functions:

\begin{enumerate}
	\item Defining a function field inside a generic class
	\lstset{style=Scala}
	\begin{lstlisting}
	def defaultCount[A](list: List[A], item: A) = list.count(_ == item)
	def customCount[A](list: List[A], item: A) = list.filter(_ == item).map((i) => 1).sum
	
	class ListTools[A] {
	val count = defaultCount[A] _ or customCount[A]
	}
	\end{lstlisting}
	\item Defining a generic method by creating the combination and then calling it immediately
	\lstset{style=Scala}
	\begin{lstlisting}
	def count[A](list: List[A], item: A) = (defaultCount _ or customCount)(list, item)
	\end{lstlisting}
\end{enumerate}


Generics solution:
\lstset{style=Scala}
\begin{lstlisting}
def defaultMap[A, B](list: List[A], fun: (A) => B): List[B] = 
list.map(fun)
def iterativeMap[A, B](list: List[A], fun: (A) => B): List[B] =  {
val result = new mutable.MutableList[B]()
for (x <- list) {
result += fun(x)
}
result.toList
}

def map[A, B](list: List[A], fun: (A) => B): List[B] = 
(defaultMap[A, B] _ or iterativeMap[A, B])(list, fun)
\end{lstlisting}

\subsection{Implicit arguments}

Implicit arguments are arguments that will be filled in automatically at invocation by an implicit method with matching signature that is available within the scope. This can be used for different reasons, but the most common is a combination with a type argument that has to have a conversion of some kind. In the Scala terminology, the type has to be \textit{viewable} as some other type. There used to be a specialized syntax called \textit{View bounds} in earlier versions of Scala to support this usage, but it has been deprecated.

%TODO: http://docs.scala-lang.org/tutorials/tour/implicit-parameters.html

\lstset{style=Scala}
\begin{lstlisting}
def bubbleSort[A <% Ordered[A]](list: List[A]): List[A] = ???
def bubbleSort[A](list: List[A])(implicit ord: A => Ordered[A]): List[A] = ???
\end{lstlisting}

The most common usage of implicit arguments is simulating \textit{type classes} from other functional languages like Haskell. We create a generic trait with required methods (representing the type class and its functions) and whenever we want a new type to be member of the type class, we create implementation of the trait and an implicit method that provides the implementation. From now on, the newly added member can be used in any method requiring the implicit conversion just by importing our conversion function into the scope where the method is called.

%TODO: Example of custom "type class" or member?

As with a lot of other features, implicit arguments are supported only by methods, not by functions. Therefore, all of them have to be resolved and fixed when performing eta-expansion, along with all the type arguments. If we set the type arguments to a concrete type, we can provide the implementation in the same way as at the time of invocation, without any problem:

\lstset{style=Scala}
\begin{lstlisting}
def radixSort(list: List[Int]): List[Int] = ???
def bubbleSort[A <% Ordered[A]](list: List[A]): List[A] = ???

val sort = radixSort _ or bubbleSort[Int]
\end{lstlisting}

%TODO: Reference
There is, however, one more option mentioned in [REFERENCE] - the type argument can be set to a type argument of an enclosing scope, making the implicit argument generic again. In this case, the scope in which the type argument is declared has to provide the implicit function implementation. As a result, the implicit argument has to be repeated in the method or class constructor signature.

\lstset{style=Scala}
\begin{lstlisting}
def implicitFun1[A](list: List[A])(implicit ord: A => Ordered[A]): List[A] = ???
def implicitFun2[A](list: List[A])(implicit ord: A => Ordered[A]): List[A] = ???

// Following line won't compile:
// def implicitFun[A](list: List[A]): List[A] = (implicitFun1[A] _ or implicitFun2[A])(list)
def implicitFun[A](list: List[A])(implicit ord: A => Ordered[A]): List[A] = (implicitFun1[A] _ or implicitFun2[A])(list)
\end{lstlisting}

\lstset{style=Scala}
\begin{lstlisting}
def bubbleSort[A](list: List[A])(implicit ord: A => Ordered[A]): List[A] = ???
\end{lstlisting}

\lstset{style=Scala}
\begin{lstlisting}
def implicitFun1[A <% Ordered[A]](list: List[A]): List[A] = ???
def implicitFun2[A <% Ordered[A]](list: List[A]): List[A] = ???

def fun = implicitFun1 _ or implicitFun2
\end{lstlisting}

Interesting thing is that the parser included in the IntelliJ IDEA IDE\footnote{Integrated Development Environment.} Scala plugin that performs background code inspection and immediately highlights compile-time errors doesn't recognize this problem. It was tested in version 2016.3.4 with Scala plugin version 2016.3.8.

%TODO: IntelliJ parser has no problems, compilation shows error

\lstset{style=Scala}
\begin{lstlisting}
def fun: (List[A]) => List[String] = implicitFun1 _ or implicitFun2
\end{lstlisting}

%TODO: Automatically generated type annotation is WRONG!!!

\subsection{Overloading}
Very similar issue is encountered when it comes to overloading - only methods can be overloaded.

%TODO: implementing traits using combined methods
\subsection{Implementing Traits}
Traits in the role of interfaces represent key element of object-oriented programming approach. Providing custom implementations of traits is essential and using adapted functions in this role would be very useful. The key problem is the separation of functions and methods in Scala mentioned in [REF].
%TODO: ADD REFERENCE HERE

The methods defined in traits can be implemented or overridden only by a different method, which will be invoked using virtual method calls. The function defined in the trait using a val keyword is basically a getter which returns the function value, invokable by itself. In this case, the getter has to be overridden, either by a custom getter, or by a field with automatically generated getter. An adapted function generated using the \lstinline|or()| method can be assigned to such a field and thus implementing the trait function getter. An example follows:

\lstset{style=Scala}
\begin{lstlisting}
trait TestTrait {
def testMethod(arg: List[Int]): List[String]
val testFunction: (List[Int]) => List[String]
}

class TestImpl extends TestTrait {
import functionadaptors.Implicits._

def impl1(arg: List[Int]): List[String] = 
arg.map("Num: " + _.toString)
def impl2(arg: List[Int]): List[String] = 
arg.map(i => s"Num: $i")

override val testFunction: (List[Int]) => List[String] = 
impl1 _ or impl2

// Can't implement testMethod using the result of or()
override def testMethod(arg: List[Int]): List[String] = ???
}
\end{lstlisting}

Unfortunately, a lot of the traits we need to provide implementations for are already existing and can use the method format. Manual workaround to implement the method is quite straightforward, but again, it generates unnecessary calls and duplicities in our code:

\lstset{style=Scala}
\begin{lstlisting}
private val adaptedFunction = impl1 _ or impl2
override def testMethod(arg: List[Int]): List[String] = 
  adaptedFunction(arg)
\end{lstlisting}

%TODO: Add reference
Or, using the solution that was previously mentioned in [PREVIOUS SECTION], we can even omit the private field declaration and use an expression syntax:

\lstset{style=Scala}
\begin{lstlisting}
override def testMethod(arg: List[Int]): List[String] = 
(impl1 _ or impl2)(arg)
\end{lstlisting}


%TODO: summary of the API approach, definition of key terms and points in adaptive lifecycle - method definition, function / closure creation (eta expansion), function combination, 

%TODO: Thread safety

\section{Run history storage location}
\label{sec:storing}

The main concern of the selection mechanism design that is invisible to the user is all the data that will be gathered at runtime and used to select the appropriate variant. Assuming we have a function combined from two different implementations and it gets invoked at various points throughout the execution of the process, we have multiple options where to store the measurements.

All of the options were actually implemented and the API allows the user to chose storage location for every usage of the combiner.

\subsection{Local}

The first and most straightforward approach is to store all the measured runtime data inside the function object itself - we have a custom type \inlinecode{FunctionAdaptor} that is hidden to the user and that carries the references to function implementation, so it could hold the measurements for them as well.

The measurement data are specific for every instance of the adaptor and limited to it. This could have some use cases, for example classes that hold immutable data and provide some functionality that is based on the contained data, which is expected to be invoked repeatedly. The run history will then be specific for the data held by the instance and thus perfectly reflect performance in this one case.

There is a limitation connected to this use case - user of the API himself has to make sure that the adaptor instance will survive and be used in every call. Let's consider the following example:

\lstset{style=Scala}
\begin{lstlisting}
def processData(data: List[Int]): Int = 
  (impl1 _ or impl2 withStorage Storage.Local)(data)
\end{lstlisting}

In this case, during every invocation of the method \inlinecode{processData}, there will be new local instance of the \inlinecode{FunctionAdaptor} created by the \inlinecode{or} call. This instance will be used for the single call and then thrown away with the measured data. In order for this example to work properly, the adaptor has to be stored away:

\lstset{style=Scala}
\begin{lstlisting}
val impl = impl1 _ or impl2 withStorage Storage.Local
def processData(data: List[Int]): Int = impl(data)
\end{lstlisting}

\subsection{Global}

Another option is to store all the measured data globally, in a static area of the memory accessible from all contexts. A unique identifier has to be used to identify every one of the functions and methods combined.

The main advantage of this approach is that the run data are collected and stored from all invocation in the entire process, so there is more data to base the decision process on. This is usually the preferred approach for some business logic or utility methods in long-running services.

\subsection{Persistent}

The globally accessible runtime data can be 

This would be most useful (and probably the only means of using the ScalaAdaptive) for short-running tools with more variants of implementing the main logic. If the logic is invoked only once (or only a couple of times) during one invocation, there will never be enough data collected in a single run and it is necessary to persist the run history, saving data from multiple runs.

As the selection algorithms are delivering better results with growing data size, persisting the run history improves the selection mechanism in all the programs.

What can be a little problematic is deciding on when to persist the data. The logical solution to minimize the time spent on writing data is to store the entire run history once at the end of execution of the program. The runtime support, however, doesn't have any method of detecting when the program is about to end - JVM doesn't guarantee finalizers being called and relying on notifications from the user would complicate the API and generally be problematic.

The other approach is to update the persisted history with every run. Its downside is that the I/O operation might have negative impact on the performance if the function is called often and its run is fast. This impact can be limited by buffering the I/O - using the default Java I/O buffering mechanism would require leaving the file open for the entire application run, so custom buffer would be preferred. The buffer could be flushed upon every n-th write.

There are more problems connected with this solution, namely:
\begin{enumerate}
\item Running multiple instances of the application at once (collisions on the persisted data file) - especially if the file is left open
\item Changes in the application code (outdated run data, changed identifiers, etc.)
\item ...
\end{enumerate}
%TODO: More

\section{Run history storage identifiers}

In the globally accessible run history data storage, the data have to be assigned to a specific function. A unique identifier that would be derivable from the function objects passed into the \inlinecode{FunctionAdaptor} is required, so that whenever an adapted function is being executed, the runtime can access its history. 

In this case, references can't be used, because the \inlinecode{FunctionAdaptor} objects and the function objects wrapped inside can exist in multiple instances, can be deallocated and reallocated.

\subsection{Type name}

Functions in Scala are instances implementing the \inlinecode{FunctionN} trait. The default implementations are anonymous closure classes that are compiled from lambda expressions. Two different functions originated in two different lambda expressions and thus have two different type names, the ones that were generated and assigned by the compiler. The fully qualified type name can be used as the identifier of a function

Using the type names as unique identifiers is safe and straightforward. A small disadvantage is that they aren't very readable, the compiler uses the name of the type that contained the lambda expression followed by sequential number. 

There is also a subtle danger connected - in case of persisting the run history, the closure classes might get renamed automatically upon recompiling. The compiler usually assigns the closure names sequentially, so this could happen by just inserting another lambda expression into the enclosing class code before the current one. Run history data might even get mixed up as the newly added lambda expression could have the former name of the original closure (by taking its position in the sequence).

If the \inlinecode{FunctionN} trait has a different than default implementation, the type name identification might fail - the trait can be implemented by a single class wrapping other values. In this case, all functions implemented by that class would share the run history.

\subsection{Method name}
\label{subsec:methodnameident}

The most common usage pattern is the one where the functions used with the \inlinecode{or} method are eta-expanded methods (see \ref{subsec:apimethods}). The eta-expansion internally replaces the method name with a lambda expression wrapping the method call into a function. Consider the following example:

\lstset{style=Scala}
\begin{lstlisting}
def method(x: Int): Int = ???
def printName[T, R](fun: (T) => R) =
  println(fun.getClass.getTypeName)
...
printName(method)
\end{lstlisting}

Line 5 will print out \textit{Test\$\$anonfun\$main\$1}, a name of a closure class generated to encapsulate lambda expression. The closure itself gets compiled and so at runtime, there is no way of finding out, which method was called inside (i.e. which method it was expanded from).

If we, in case of eta-expanded methods, use the type name identifier, we run into a little problem - if a method is used in multiple \inlinecode{or} expressions, a different closure class is generated for each expression where it's eta-expanded. So in the following example, run history data of \inlinecode{method1} wouldn't be shared for runs originating from \inlinecode{combined1} and \inlinecode{combined2}:

\lstset{style=Scala}
\begin{lstlisting}
val combined1 = method1 _ or method2
val combined2 = method1 _ or method3
\end{lstlisting}

More convenient would be to use directly the names of the methods that are being eta-expanded. The names have to be extracted at compile time, using the def macros (see \ref{sec:defmacros}). At the moment of implicit conversion from \inlinecode{FunctionN} to \inlinecode{FunctionAdapterN}, the AST\footnote{Abstract syntax tree.} of the \inlinecode{FunctionN} expression can be examined - if it's a lambda expression containing one method call, the method name can be extracted.

Using method name identifier has some disadvantages as well. Firstly, all method overloads share the same identifier. Additionally, generic type arguments are not included in the identifier either.

\subsection{Custom identifier}

In order to handle the specific cases where type name and method name identifiers don't distinguish correctly between different functions, there is also a possibility of choosing a custom, arbitrary identifier. This has to be triggered specifically by the user in the API and should be used in the cases where:

\begin{enumerate}
	\item User knows that the automatically assigned identifiers won't be sufficient
	\item User wants to replace default type identifier with custom identifier because of readability
\end{enumerate}

%TODO: Evaluation, advantages, disadvantages, generation

\section{Extracting method name from eta-expansion AST}

In order to retrieve the method name to be used as an identifier (as explained in \ref{subsec:methodnameident}), we need to do the following:

\begin{enumerate}
	\item Replace the implicit conversion method from \inlinecode{FunctionN} to \inlinecode{FunctionAdaptorN} by a def macro (see \ref{sec:defmacros})
	\item Inside the macro, analyze the AST, detect eta-expansion method call
	\item If there is a method call:
	\begin{enumerate}
		\item Generate the identifier expression as a \inlinecode{getTypeName} call on the target of the method call, followed by the method name
		\item Generate the conversion code with explicitly specified reference expression
	\end{enumerate}
	\item Otherwise generate the conversion code with implicit reference	
\end{enumerate}

The conversion is done using the \inlinecode{toAdapter()} method with two overloads:
\begin{itemize}
	\item Accepting only the function - implicit reference is used (type name of the closure)
	\item Accepting the function and a custom reference - the reference provided is used
\end{itemize}

\subsection{Eta-expansion AST format}

First step in the macro implementation has to be parsing the input AST and detecting patterns that are generated from eta-expansions by the compiler. Using the \inlinecode{printAst()} macro mentioned in \ref{subsec:buildingast}, the following facts were discovered:

\begin{itemize}
	\item The eta-expansion is already replaced by the equivalent code in AST, so it can't be detected directly.
	\item The result of eta-expansion is a lambda expression (function literal).
\lstset{style=Dump}
\begin{lstlisting}
Function(...)
\end{lstlisting}
	\item The lambda expression is always wrapped in a block, being its return value.
	
\lstset{style=Dump}
\begin{lstlisting}
Block(
  List(...), 
  Function(...))
\end{lstlisting}	
	
	\item If the target of the invocation is either a constant or \textit{this}, it is captured in the lambda expression closure (i.e., the constant or \textit{this} is referenced directly from the function body).
	
	\item If the target of the invocation is a variable or a result of a more complicated expression, it is extracted to the enclosing block, its result is stored in a variable local to the block and then captured in the lambda expression closure. The reason is probably to avoid multiple evaluation of expressions with possible side-efects upon every invocation of the resulting function, and to avoid the target being changed throughout the lifetime of the function.
	
\lstset{style=Dump}
\begin{lstlisting}
Block(
  List(
    ValDef(
      Modifiers(SYNTHETIC), 
      TermName("eta$0$1"), 
      TypeTree(), 
      Apply(
        Select(
          This(
            TypeName("ClassName")), 
          TermName("getClassInstance")), 
        List()))), 
  Function(...))
\end{lstlisting}

	\item The function node contains argument definition and the expression itself, which is a single function application.

\lstset{style=Dump}
\begin{lstlisting}
Function(
  List(
    ValDef(
      Modifiers(PARAM | SYNTHETIC), 
      TermName("arg"), 
      TypeTree(), 
      EmptyTree)), 
  Apply(...))
\end{lstlisting}

	
%	\item The lambda expression (function literal) generated for the eta-expansion contains only the method invocation and the type applications (if the method is generic) - all the other expressions that are part of the eta-expansion are extracted to an outer, enclosing block, their results are stored in variables local to the block and then captured in the lambda expression closure. The reason is probably to avoid multiple evaluation of expressions with possible side-efects upon every invocation of the resulting function.
\end{itemize}

This has a few consequences for our case. We need to generate our conversion and method retrieval code into the block return value, because we need to be able to access the invocation targets that can be defined in the block itself. The target and the method name will always be in the single Apply node representing the function body.

If the method doesn't accept any type arguments, the tree is quite simple:

\lstset{style=Dump}
\begin{lstlisting}
Apply(
  Select(
    ...invocation target expression..., 
    TermName("methodName")), 
  List(...function arguments...))
\end{lstlisting}

Where the \textit{invocation target expression} can have multiple forms based on the original expression, and can depend on the enclosing block variables. It isn't, however, important for us, as we can work with the expression as whole. The function arguments are not needed either.

If the method is generic, the type arguments need to be applied in order to convert it to a function (which can't be generic). In this case, the tree gets a little more complicated:

\lstset{style=Dump}
\begin{lstlisting}
Apply(
  TypeApply(
    Select(
      ...invocation target expression..., 
      TermName("genericMethod")), 
    List(...type arguments...))), 
  List(...function arguments...))
\end{lstlisting}

The method call is wrapped in a TypeApply node before being invoked using the Apply node. The TypeApply node can in our case be ignored.

And the most complicated case we can encounter is when the method has some implicit arguments as well:

\lstset{style=Dump}
\begin{lstlisting}
Apply(
  Apply(
    TypeApply(
      Select(
        ...invocation target expression...,
        TermName("genericMethodImplicit")), 
      List(...type arguments...)), 
    List(...function arguments...)), 
  List(...implicit arguments...))
\end{lstlisting}

One more Apply node is added to the topmost level - the implicit arguments are applied after applying the actual function arguments. Their definition contains another nested block and lambda expression, but again, it is not necessary for our case. We just need to extract the invocation target and the method name.

\subsection{Generating the conversion}

Supposing we have the invocation target expression and the method name, we need to create the identifier string expression that will be used in the manual \inlinecode{toAdapter} invocation.

In order to extract the fully qualified name of the method call target, we need to generate the following expression:

\lstset{style=Scala}
\begin{lstlisting}
invocationTarget.getClass.getTypeName + ".methodName"
\end{lstlisting}

The AST representing this expression has to be wrapped in the \inlinecode{MethodNameReference} construction application (it is a case class with automatically generated \inlinecode{apply()} method) to get the resulting reference.

In all the cases, the \inlinecode{toAdapter} method has to be generated to replace the macro function. The function literal from the original AST has to be passed in as the first argument, and optionally, the second argument can be provided if the extraction of the method name was successful.

The original simplified tree looks like this:

\begin{forest}
	[Block
	  [Statements
	    [ValDef]
	  ]
	  [Function]
	]
\end{forest}

We need to transform the block, keeping the definition in the statement part, but wrapping the \inlinecode{Function} into the \inlinecode{toAdapter} call.
	
\begin{forest}
	[Block
	[Statements
	[ValDef]
	]
	[Apply
	  [toAdaptor]
	  [ArgumentList
	    [Function]
	    [ExtractedReferenceExpression]
	  ]
	]
	]
\end{forest}

\subsection{Extracting method overloads}

The approach that was described so far has one small issue - it doesn't recognize function overloads, so all the overloads share the same identifier.

 It wouldn't be difficult to extract the actual number of arguments that the method is being invoked with and include it in the reference. When attempting to extract the argument types of the lambda expression, we encounter a major problem - the function literal is generated without argument type specification, the TypeTree is empty:

\lstset{style=Dump}
\begin{lstlisting}
ValDef(
  Modifiers(PARAM | SYNTHETIC), 
  TermName("i"), 
  TypeTree(), 
  EmptyTree)
\end{lstlisting}

This can be done and is quite similar to the following piece of code:

\lstset{style=Scala}
\begin{lstlisting}
val function: (Int) => Int = { i => math.abs(i) + 1 }
\end{lstlisting}

In this case, the lambda expression doesn't have the type of its arguments specified either, because the compiler will infer it from the context in which the expression is used, in this case, from the type specifier of the variable.

The compiler is able to infer the data type from the usage of the argument as well:
\lstset{style=Scala}
\begin{lstlisting}
def method(i: Int): Int = ???
val function = { i => method(i) }
\end{lstlisting}

The previous piece of code is correctly compiled by the Scala compiler, although some IDEs (namely IntelliJ IDEA 2016.3.4) aren't able to infer the type and mark the code as incorrect.

Note that the eta-expansion is guided by the same rules, so whenever expanding a method without overloads, the compiler infers the types by itself:
\lstset{style=Scala}
\begin{lstlisting}
def method(i: Int): Int = ???
val function = method _
\end{lstlisting}

Upon expansion of a method with overloads, the resulting function type has to be provided and the inference flow goes in the other direction:
\lstset{style=Scala}
\begin{lstlisting}
def method(i: Int): Int = ???
def method(s: String): Int = ???
val function: (String) => Int = method _
\end{lstlisting}

As a consequence, at the time of syntax analysis, the types aren't inferred yet and there is no way for us to find out which method overload is being called.

The method overloads have to share the same identifier, but in most typical cases, this isn't a problem. Otherwise, it can be solved by using custom identifiers.
	
\section{Delayed measuring}
\label{sec:delayed_measuring}

In some specific cases it might be useful to delay the measurement, or, in general, to measure invocation of a different function than the one that has multiple implementation. The implementations can affect something else than their own runtime. Some example use cases might be:

\begin{itemize}
	\item Configuration, or generation of configuration
	\item Expression tree building
	\item Query building
	\item Method chain building
\end{itemize}

It is obvious that our API, which was designed to remain as simple as possible, doesn't support this case. We need to slightly extend it.

\subsection{Decision context}

Supposing we already have a mechanism to mark the actual function to measure, we encounter another problem. Making a decision when executing the function with multiple implementation automatically generates a context of the decision - all measured function invocations that were affected by the decision. When measuring the invocation, the library has to know to which context it belongs in order to be able to assign the measured data to the run history of the corresponding function.

The contexts can interleave and we can't match the decision with the invocation by time or location. It is impossible to decide to which decision which invocation belongs automatically - we need support from the library user. The user will have to explicitly state the context whenever invoking the measured function. By doing this, he will pinpoint the moment of decision that affected the invocation.

Practically, we need to introduce a special object - the \textbf{measurement token} - which will represent the context. The \inlinecode{MultiFunction} instances will have a special, modified version of the apply method, which will not trigger the measure of the selected function, but will generate a measurement token, that will be used to measure future function runs.

\lstset{style=Scala}
\begin{lstlisting}
val getConfig = getFastConfig _ or getSlowConfig
val (config, measure) = getConfig^()
...
measure(() => run(config))
\end{lstlisting}

This approach has one main disadvantage compared to the rest of the API - it isn't transparent. The user has to know that he is working with the \inlinecode{MultiFunction}, not just normal function. His assistance is, however, required by the nature of the problem.

%TODO: Use cases - configuration generation, expression tree building, query building...

%TODO: Problems - matching decision with measurement

\section{Macros in API}

%TODO: implicit conversions as macros, other problems arising