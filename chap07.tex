\chapter{Related work}

A different approach for the same goal consists in manually selecting an implementation and guaranteeing its performance with unit tests. A special language, SPL (Stochastic Performance Logic), which allows to express assumptions about the performance of multiple functions, was introduced in \cite{bulej_capturing_2012}. The innovative concept is that it treats the performance as a random variable, not as a fixed value, so the conditions are evaluated with certain confidence. It was later used to examine the performance of JDOM framework in \cite{horky_performance_2013}, and became the base of performance unit testing frameworks for C\# (\cite{Trojanek:Thesis:2013}) and Java (\cite{Kotrc:Thesis:2015}).

The development of adaptive systems that can tweak their performance based on the environment is a widely studied topic as well. Systems that are capable of some form of \textit{auto-tunning}, i.e., self reconfiguration based on an analysis of the execution environment (OS, CPU, etc...), are often among the fastest in its category - an example might be \cite{frigo_fftw:_1998},  which is considered to be the fastest non-commercial FFT\footnote{Fast Fourier transform} algorithm in the world. The adaptation in this case is done by recompiling the application code (\cite{frigo_fast_1999}).

An idea of a universal adaptive framework that would not require manual analysis of the environment and work only with observations from actual execution is presented in \cite{bulej_performance_2012}. It describes a system that has generally the same goal as our work - increase performance awareness by designing the systems adaptively. It is focused on large component-based applications where the performance of certain components is tracked. Multiple use case scenarios are presented, e.g. verifying component contract, observing trends, or selecting between multiple interchangeable components based on performance. The SPL is used to make the decisions, i.e., the components are guarded by conditions expressed in the language.

The article does not solve the issue of predicting run time with a certain input based on the performance observed with other inputs. The presented concept is also based on the interconnection between the adaptive framework and the system components. ScalaAdaptive provides a partial implementation of a similar system, more narrowly focused, with higher emphasis on the simplicity and efficiency of performing the single task of selecting faster implementation. In addition, it provides an API that allows easily using the adaptivity in any existing system with no need of architectural changes.

The task of predicting function (or application in general) run time based on the input is a separate problem examined in many different ways. In \cite{wegbreit_mechanical_1975}, a static analysis of LISP programs is performed in order to derive actual complexity. A runtime analysis approach was taken in \cite{goldsmith_measuring_2007}, where basic blocks in the program called \textit{locations} are identified and their performance is measured for a certain input described by a set of \textit{features}. The performance is represented by an execution count in order to keep the measurement deterministic and platform or environment independent. A powerlaw regression is then built to find relations between \textit{feature} values and \textit{locations}. The resulting model can be used to formulate predictions.

Relatively precise predictions of an actual execution can be achieved using the Mantis framework \cite{chun_mantis:_2010}, which is based on instrumenting the code and automatically identifying its \textit{features} (loops, branches, variable values\dots). The \textit{features} are evaluated (branch counts, loop counts\dots) at runtime and the machine learning process is used to select the ones that are important for the overall performance. A regression model is then constructed using the data. One of the possible models is described in \cite{huang_predicting_2010}.

Authors of \cite{smith_predicting_1998} obtain the predictions in two steps - first, they use greedy or genetic algorithm to find similar inputs (jobs, workloads) in the historical run measurement, and then, they generate the prediction using either simple mean or inear regression, both with corresponding confidence interval. The basic approach taken here is quite similar to the ScalaAdaptive, even though neither this, nor the other works referenced in this chapter deal with the problem of real-time prediction upon invocation, where one of the main concerns is minimizing the overhead.